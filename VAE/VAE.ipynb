{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNiAWfKQZZqE4J/E3dDBLh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cohitai/AI_notebooks/blob/main/VAE/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variational AutoEncoder = (encoder= Recognition model, decoder=Generative model)+ Variational loss.\n",
        "\n",
        " Variational loss = ELBO (evidence lower bound).\n",
        "\n"
      ],
      "metadata": {
        "id": "TjIgUpV0H-Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ToDO: visualizations of the latent space, KL divergence explanations, Generative data. \n",
        "### Go over these: \n",
        "# Not sure I have the \"right\" variational loss. \n",
        "# https://avandekleut.github.io/vae/\n",
        "# https://www.jeremyjordan.me/variational-autoencoders/\n",
        "# https://gaussian37.github.io/deep-learning-chollet-8-4/\n",
        "# simplify NN ? (How many ResNet layers/Blocks? are actiually meaningfull for a baseline.)\n",
        "# output doesn't converge well. (check loss ? epochs adjustments/learning rate?)\n",
        "# plot the loss\n",
        "# change reconstruction loss to recons_loss =F.mse_loss(recons, input).\n",
        "\n",
        "# The loss depends heavily on the BS. \n",
        "# Compare the loss with the pretrained VAE model(Huggingfaces). \n",
        "# sum() or mean() in loss , and kl.sum() or kl.mean() ? \n"
      ],
      "metadata": {
        "id": "VrgX3VIFo8Dk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "\n",
        "print(\"Working directory:\", os.getcwd())\n",
        "device=\"cuda\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMwmbbQMWjkm",
        "outputId": "b7e96937-9591-4d3b-cba8-fc151eb4530f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-ZChfoGGKpW",
        "outputId": "aa663854-d4f3-4473-f035-63329a881c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 14 16:13:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## download cifar10 data"
      ],
      "metadata": {
        "id": "n4Av47HCGOzs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsU_bddeG5hg",
        "outputId": "537bee0f-c3f9-4fb2-c67d-55bcdfc6906b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-14 11:42:17--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  86.9MB/s    in 1.9s    \n",
            "\n",
            "2022-11-14 11:42:19 (86.9 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg1DtEo7Hv3J",
        "outputId": "e955f4be-97e2-466b-f859-7d5ca1a96a4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10-python.tar.gz\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvf cifar-10-python.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TcMrBWwH0kb",
        "outputId": "d7326da6-0637-4398-a543-8d85bade7fdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls -al cifar-10-batches-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELnbEiF2IL_6",
        "outputId": "41978291-fe3f-4fab-ab93-8de3d1f7a8cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 181884\n",
            "drwxr-xr-x 2 2156 1103     4096 Jun  4  2009 .\n",
            "drwxr-xr-x 1 root root     4096 Nov 14 11:42 ..\n",
            "-rw-r--r-- 1 2156 1103      158 Mar 31  2009 batches.meta\n",
            "-rw-r--r-- 1 2156 1103 31035704 Mar 31  2009 data_batch_1\n",
            "-rw-r--r-- 1 2156 1103 31035320 Mar 31  2009 data_batch_2\n",
            "-rw-r--r-- 1 2156 1103 31035999 Mar 31  2009 data_batch_3\n",
            "-rw-r--r-- 1 2156 1103 31035696 Mar 31  2009 data_batch_4\n",
            "-rw-r--r-- 1 2156 1103 31035623 Mar 31  2009 data_batch_5\n",
            "-rw-r--r-- 1 2156 1103       88 Jun  4  2009 readme.html\n",
            "-rw-r--r-- 1 2156 1103 31035526 Mar 31  2009 test_batch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os.path as osp\n",
        "# path = \"./cifar-10-batches-py\"\n",
        "# def unpickle(file):\n",
        "#     import pickle\n",
        "#     with open(file, 'rb') as fo:\n",
        "#         dict = pickle.load(fo, encoding='bytes')\n",
        "#     return dict\n",
        "\n",
        "# !ls $path\n",
        "\n",
        "# c10_data = unpickle(osp.join(path,\"data_batch_1\"))\n",
        "# print(c10_data.keys())\n",
        "\n",
        "# # extract c10 data --> images,labels\n",
        "# images = c10_data[b\"data\"].reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\") # (10000,3072)\n",
        "# labels = c10_data[b\"labels\"]\n",
        "# #\n",
        "# print(\"Data Shape\",images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poZc6mX8IP1H",
        "outputId": "8a8a9c41-55b1-4255-c5a3-ba73be2e5e8b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batches.meta  data_batch_2  data_batch_4  readme.html\n",
            "data_batch_1  data_batch_3  data_batch_5  test_batch\n",
            "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
            "Data Shape (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Blocks: - DownEncoderBlock2D\n",
        "              - UpDecoderBlock2D\n",
        "              - ResnetBlock\n",
        "              - Downsample2D\n",
        "              - Upsample2D\n",
        "              - AttentionBlockNew\n",
        "              - UNetMidBlock2D\n",
        "              - Encoder\n",
        "              - Decoder"
      ],
      "metadata": {
        "id": "JZ3V7x4oWwCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DownEncoderBlock2D(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        dropout: float = 0.0, \n",
        "        num_layers: int = 1,\n",
        "        resnet_eps: float = 1e-6,\n",
        "        resnet_time_scale_shift: str = \"default\",\n",
        "        resnet_act_fn: str = \"swish\",\n",
        "        resnet_groups: int = 32,\n",
        "        resnet_pre_norm: bool = True,\n",
        "        output_scale_factor=1.0,\n",
        "        add_downsample=True,\n",
        "        downsample_padding=1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        resnets = []\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            in_channels = in_channels if i == 0 else out_channels\n",
        "            resnets.append(\n",
        "                ResnetBlock(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=out_channels,\n",
        "                    temb_channels=None,\n",
        "                    eps=resnet_eps,\n",
        "                    groups=resnet_groups,\n",
        "                    dropout=dropout,\n",
        "                    time_embedding_norm=resnet_time_scale_shift,\n",
        "                    non_linearity=resnet_act_fn,\n",
        "                    output_scale_factor=output_scale_factor,\n",
        "                    pre_norm=resnet_pre_norm,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.resnets = nn.ModuleList(resnets)\n",
        "\n",
        "        if add_downsample:\n",
        "            self.downsamplers = nn.ModuleList(\n",
        "                [\n",
        "                    Downsample2D(\n",
        "                        in_channels, use_conv=True, out_channels=out_channels, padding=downsample_padding, name=\"op\"\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        else:\n",
        "            self.downsamplers = None\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        for resnet in self.resnets:\n",
        "            hidden_states = resnet(hidden_states, temb=None)\n",
        "\n",
        "        if self.downsamplers is not None:\n",
        "            for downsampler in self.downsamplers:\n",
        "                hidden_states = downsampler(hidden_states)\n",
        "\n",
        "        return hidden_states\n",
        "\n",
        "class UpDecoderBlock2D(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        dropout: float = 0.0,\n",
        "        num_layers: int = 1,\n",
        "        resnet_eps: float = 1e-6,\n",
        "        resnet_time_scale_shift: str = \"default\",\n",
        "        resnet_act_fn: str = \"swish\",\n",
        "        resnet_groups: int = 32,\n",
        "        resnet_pre_norm: bool = True,\n",
        "        output_scale_factor=1.0,\n",
        "        add_upsample=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        resnets = []\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            input_channels = in_channels if i == 0 else out_channels\n",
        "\n",
        "            resnets.append(\n",
        "                ResnetBlock(\n",
        "                    in_channels=input_channels,\n",
        "                    out_channels=out_channels,\n",
        "                    temb_channels=None,\n",
        "                    eps=resnet_eps,\n",
        "                    groups=resnet_groups,\n",
        "                    dropout=dropout,\n",
        "                    time_embedding_norm=resnet_time_scale_shift,\n",
        "                    non_linearity=resnet_act_fn,\n",
        "                    output_scale_factor=output_scale_factor,\n",
        "                    pre_norm=resnet_pre_norm,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.resnets = nn.ModuleList(resnets)\n",
        "\n",
        "        if add_upsample:\n",
        "            self.upsamplers = nn.ModuleList([Upsample2D(out_channels, use_conv=True, out_channels=out_channels)])\n",
        "        else:\n",
        "            self.upsamplers = None\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        for resnet in self.resnets:\n",
        "            hidden_states = resnet(hidden_states, temb=None)\n",
        "\n",
        "        if self.upsamplers is not None:\n",
        "            for upsampler in self.upsamplers:\n",
        "                hidden_states = upsampler(hidden_states)\n",
        "\n",
        "        return hidden_states\n",
        "\n",
        "  \n",
        "    \n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        in_channels,\n",
        "        out_channels=None,\n",
        "        conv_shortcut=False,\n",
        "        dropout=0.0,\n",
        "        temb_channels=512,\n",
        "        groups=32,\n",
        "        groups_out=None,\n",
        "        pre_norm=True,\n",
        "        eps=1e-6,\n",
        "        non_linearity=\"swish\",\n",
        "        time_embedding_norm=\"default\",\n",
        "        kernel=None,\n",
        "        output_scale_factor=1.0,\n",
        "        use_nin_shortcut=None,\n",
        "        up=False,\n",
        "        down=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.pre_norm = pre_norm\n",
        "        self.pre_norm = True\n",
        "        self.in_channels = in_channels\n",
        "        out_channels = in_channels if out_channels is None else out_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.use_conv_shortcut = conv_shortcut\n",
        "        self.time_embedding_norm = time_embedding_norm\n",
        "        self.up = up\n",
        "        self.down = down\n",
        "        self.output_scale_factor = output_scale_factor\n",
        "\n",
        "        if groups_out is None:\n",
        "            groups_out = groups\n",
        "\n",
        "        self.norm1 = torch.nn.GroupNorm(num_groups=groups, num_channels=in_channels, eps=eps, affine=True)\n",
        "\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        if temb_channels is not None:\n",
        "            self.time_emb_proj = torch.nn.Linear(temb_channels, out_channels)\n",
        "        else:\n",
        "            self.time_emb_proj = None\n",
        "\n",
        "        self.norm2 = torch.nn.GroupNorm(num_groups=groups_out, num_channels=out_channels, eps=eps, affine=True)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        if non_linearity == \"swish\":\n",
        "            self.nonlinearity = lambda x: F.silu(x)\n",
        "        elif non_linearity == \"mish\":\n",
        "            self.nonlinearity = Mish()\n",
        "        elif non_linearity == \"silu\":\n",
        "            self.nonlinearity = nn.SiLU()\n",
        "\n",
        "        self.upsample = self.downsample = None\n",
        "        if self.up:\n",
        "            if kernel == \"fir\":\n",
        "                fir_kernel = (1, 3, 3, 1)\n",
        "                self.upsample = lambda x: upsample_2d(x, k=fir_kernel)\n",
        "            elif kernel == \"sde_vp\":\n",
        "                self.upsample = partial(F.interpolate, scale_factor=2.0, mode=\"nearest\")\n",
        "            else:\n",
        "                self.upsample = Upsample2D(in_channels, use_conv=False)\n",
        "        \n",
        "        elif self.down:\n",
        "            if kernel == \"fir\":\n",
        "                fir_kernel = (1, 3, 3, 1)\n",
        "                self.downsample = lambda x: downsample_2d(x, k=fir_kernel)\n",
        "            elif kernel == \"sde_vp\":\n",
        "                self.downsample = partial(F.avg_pool2d, kernel_size=2, stride=2)\n",
        "            else:\n",
        "                self.downsample = Downsample2D(in_channels, use_conv=False, padding=1, name=\"op\")\n",
        "\n",
        "        self.use_nin_shortcut = self.in_channels != self.out_channels if use_nin_shortcut is None else use_nin_shortcut\n",
        "\n",
        "        self.conv_shortcut = None\n",
        "    \n",
        "        if self.use_nin_shortcut:\n",
        "            self.conv_shortcut = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x, temb, hey=False):\n",
        "        h = x\n",
        "\n",
        "        # print(\"LOG resnet_input\",h.size())\n",
        "\n",
        "        # make sure hidden states is in float32\n",
        "        # when running in half-precision\n",
        "        h = self.norm1(h.float()).type(h.dtype)\n",
        "        h = self.nonlinearity(h)\n",
        "\n",
        "        # if self.upsample is not None:\n",
        "        #     x = self.upsample(x)\n",
        "        #     h = self.upsample(h)\n",
        "        # elif self.downsample is not None:\n",
        "        #     x = self.downsample(x)\n",
        "        #     h = self.downsample(h)\n",
        "\n",
        "        h = self.conv1(h)\n",
        "\n",
        "        # print(\"LOG temb:\",temb is None)\n",
        "\n",
        "        # if temb is not None:\n",
        "        #     temb = self.time_emb_proj(self.nonlinearity(temb))[:, :, None, None]\n",
        "        #     h = h + temb\n",
        "\n",
        "        # make sure hidden states is in float32\n",
        "        # when running in half-precision\n",
        "        h = self.norm2(h.float()).type(h.dtype)\n",
        "        h = self.nonlinearity(h)\n",
        "\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv2(h)\n",
        "\n",
        "        if self.conv_shortcut is not None:\n",
        "            x = self.conv_shortcut(x)\n",
        "\n",
        "        out = (x + h) / self.output_scale_factor\n",
        "\n",
        "        return out\n",
        "\n",
        "    def set_weight(self, resnet):\n",
        "        self.norm1.weight.data = resnet.norm1.weight.data\n",
        "        self.norm1.bias.data = resnet.norm1.bias.data\n",
        "\n",
        "        self.conv1.weight.data = resnet.conv1.weight.data\n",
        "        self.conv1.bias.data = resnet.conv1.bias.data\n",
        "\n",
        "        if self.time_emb_proj is not None:\n",
        "            self.time_emb_proj.weight.data = resnet.temb_proj.weight.data\n",
        "            self.time_emb_proj.bias.data = resnet.temb_proj.bias.data\n",
        "\n",
        "        self.norm2.weight.data = resnet.norm2.weight.data\n",
        "        self.norm2.bias.data = resnet.norm2.bias.data\n",
        "\n",
        "        self.conv2.weight.data = resnet.conv2.weight.data\n",
        "        self.conv2.bias.data = resnet.conv2.bias.data\n",
        "\n",
        "        if self.use_nin_shortcut:\n",
        "            self.conv_shortcut.weight.data = resnet.nin_shortcut.weight.data\n",
        "            self.conv_shortcut.bias.data = resnet.nin_shortcut.bias.data\n",
        "            \n",
        "            \n",
        "class Downsample2D(nn.Module):\n",
        "    \"\"\"\n",
        "    A downsampling layer with an optional convolution.\n",
        "    :param channels: channels in the inputs and outputs. :param use_conv: a bool determining if a convolution is\n",
        "    applied. :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then\n",
        "                 downsampling occurs in the inner-two dimensions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels, use_conv=False, out_channels=None, padding=1, name=\"conv\"):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.out_channels = out_channels or channels\n",
        "        self.use_conv = use_conv\n",
        "        self.padding = padding\n",
        "        stride = 2\n",
        "        self.name = name\n",
        "\n",
        "        if use_conv:\n",
        "            conv = nn.Conv2d(self.channels, self.out_channels, 3, stride=stride, padding=padding)\n",
        "        else:\n",
        "            assert self.channels == self.out_channels\n",
        "            conv = nn.AvgPool2d(kernel_size=stride, stride=stride)\n",
        "\n",
        "        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n",
        "        if name == \"conv\":\n",
        "            self.Conv2d_0 = conv\n",
        "            self.conv = conv\n",
        "        elif name == \"Conv2d_0\":\n",
        "            self.conv = conv\n",
        "        else:\n",
        "            self.conv = conv\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.shape[1] == self.channels\n",
        "        if self.use_conv and self.padding == 0:\n",
        "            pad = (0, 1, 0, 1)\n",
        "            x = F.pad(x, pad, mode=\"constant\", value=0)\n",
        "\n",
        "        assert x.shape[1] == self.channels\n",
        "        x = self.conv(x)\n",
        "\n",
        "        # print('LOG',x)\n",
        "        return x\n",
        "\n",
        "class Upsample2D(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    An upsampling layer with an optional convolution.\n",
        "    :param channels: channels in the inputs and outputs. :param use_conv: a bool determining if a convolution is\n",
        "    applied. :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then\n",
        "                 upsampling occurs in the inner-two dimensions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels, use_conv=False, use_conv_transpose=False, out_channels=None, name=\"conv\"):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.out_channels = out_channels or channels\n",
        "        self.use_conv = use_conv\n",
        "        self.use_conv_transpose = use_conv_transpose\n",
        "        self.name = name\n",
        "\n",
        "        conv = None\n",
        "        if use_conv_transpose:\n",
        "            conv = nn.ConvTranspose2d(channels, self.out_channels, 4, 2, 1)\n",
        "        elif use_conv:\n",
        "            conv = nn.Conv2d(self.channels, self.out_channels, 3, padding=1)\n",
        "\n",
        "        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n",
        "        if name == \"conv\":\n",
        "            self.conv = conv\n",
        "        else:\n",
        "            self.Conv2d_0 = conv\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.shape[1] == self.channels\n",
        "        if self.use_conv_transpose:\n",
        "            return self.conv(x)\n",
        "\n",
        "        x = F.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n",
        "\n",
        "        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n",
        "        if self.use_conv:\n",
        "            if self.name == \"conv\":\n",
        "                x = self.conv(x)\n",
        "            else:\n",
        "                x = self.Conv2d_0(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttentionBlockNew(nn.Module):\n",
        "    \"\"\"\n",
        "    An attention block that allows spatial positions to attend to each other. Originally ported from here, but adapted\n",
        "    to the N-d case.\n",
        "    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/models/unet.py#L66.\n",
        "    Uses three q, k, v linear layers to compute attention\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels,\n",
        "        num_head_channels=None,\n",
        "        num_groups=32,\n",
        "        rescale_output_factor=1.0,\n",
        "        eps=1e-5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "\n",
        "        self.num_heads = channels // num_head_channels if num_head_channels is not None else 1\n",
        "        self.num_head_size = num_head_channels\n",
        "        self.group_norm = nn.GroupNorm(num_channels=channels, num_groups=num_groups, eps=eps, affine=True)\n",
        "\n",
        "        # define q,k,v as linear layers\n",
        "        self.query = nn.Linear(channels, channels)\n",
        "        self.key = nn.Linear(channels, channels)\n",
        "        self.value = nn.Linear(channels, channels)\n",
        "\n",
        "        self.rescale_output_factor = rescale_output_factor\n",
        "        self.proj_attn = nn.Linear(channels, channels, 1)\n",
        "\n",
        "    def transpose_for_scores(self, projection: torch.Tensor) -> torch.Tensor:\n",
        "        new_projection_shape = projection.size()[:-1] + (self.num_heads, -1)\n",
        "        # move heads to 2nd position (B, T, H * D) -> (B, T, H, D) -> (B, H, T, D)\n",
        "        new_projection = projection.view(new_projection_shape).permute(0, 2, 1, 3)\n",
        "        return new_projection\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        residual = hidden_states\n",
        "        batch, channel, height, width = hidden_states.shape\n",
        "\n",
        "        # norm\n",
        "        hidden_states = self.group_norm(hidden_states)\n",
        "\n",
        "        hidden_states = hidden_states.view(batch, channel, height * width).transpose(1, 2)\n",
        "\n",
        "        # proj to q, k, v\n",
        "        query_proj = self.query(hidden_states)\n",
        "        key_proj = self.key(hidden_states)\n",
        "        value_proj = self.value(hidden_states)\n",
        "\n",
        "        # transpose\n",
        "        query_states = self.transpose_for_scores(query_proj)\n",
        "        key_states = self.transpose_for_scores(key_proj)\n",
        "        value_states = self.transpose_for_scores(value_proj)\n",
        "\n",
        "        # get scores\n",
        "        scale = 1 / math.sqrt(math.sqrt(self.channels / self.num_heads))\n",
        "        attention_scores = torch.matmul(query_states * scale, key_states.transpose(-1, -2) * scale)\n",
        "        attention_probs = torch.softmax(attention_scores.float(), dim=-1).type(attention_scores.dtype)\n",
        "\n",
        "        # compute attention output\n",
        "        context_states = torch.matmul(attention_probs, value_states)\n",
        "\n",
        "        context_states = context_states.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_states_shape = context_states.size()[:-2] + (self.channels,)\n",
        "        context_states = context_states.view(new_context_states_shape)\n",
        "\n",
        "        # compute next hidden_states\n",
        "        hidden_states = self.proj_attn(context_states)\n",
        "        hidden_states = hidden_states.transpose(-1, -2).reshape(batch, channel, height, width)\n",
        "\n",
        "        # res connect and rescale\n",
        "        hidden_states = (hidden_states + residual) / self.rescale_output_factor\n",
        "        return hidden_states\n",
        "\n",
        "    def set_weight(self, attn_layer):\n",
        "        self.group_norm.weight.data = attn_layer.norm.weight.data\n",
        "        self.group_norm.bias.data = attn_layer.norm.bias.data\n",
        "\n",
        "        if hasattr(attn_layer, \"q\"):\n",
        "            self.query.weight.data = attn_layer.q.weight.data[:, :, 0, 0]\n",
        "            self.key.weight.data = attn_layer.k.weight.data[:, :, 0, 0]\n",
        "            self.value.weight.data = attn_layer.v.weight.data[:, :, 0, 0]\n",
        "\n",
        "            self.query.bias.data = attn_layer.q.bias.data\n",
        "            self.key.bias.data = attn_layer.k.bias.data\n",
        "            self.value.bias.data = attn_layer.v.bias.data\n",
        "\n",
        "            self.proj_attn.weight.data = attn_layer.proj_out.weight.data[:, :, 0, 0]\n",
        "            self.proj_attn.bias.data = attn_layer.proj_out.bias.data\n",
        "        elif hasattr(attn_layer, \"NIN_0\"):\n",
        "            self.query.weight.data = attn_layer.NIN_0.W.data.T\n",
        "            self.key.weight.data = attn_layer.NIN_1.W.data.T\n",
        "            self.value.weight.data = attn_layer.NIN_2.W.data.T\n",
        "\n",
        "            self.query.bias.data = attn_layer.NIN_0.b.data\n",
        "            self.key.bias.data = attn_layer.NIN_1.b.data\n",
        "            self.value.bias.data = attn_layer.NIN_2.b.data\n",
        "\n",
        "            self.proj_attn.weight.data = attn_layer.NIN_3.W.data.T\n",
        "            self.proj_attn.bias.data = attn_layer.NIN_3.b.data\n",
        "\n",
        "            self.group_norm.weight.data = attn_layer.GroupNorm_0.weight.data\n",
        "            self.group_norm.bias.data = attn_layer.GroupNorm_0.bias.data\n",
        "        else:\n",
        "            qkv_weight = attn_layer.qkv.weight.data.reshape(\n",
        "                self.num_heads, 3 * self.channels // self.num_heads, self.channels\n",
        "            )\n",
        "            qkv_bias = attn_layer.qkv.bias.data.reshape(self.num_heads, 3 * self.channels // self.num_heads)\n",
        "\n",
        "            q_w, k_w, v_w = qkv_weight.split(self.channels // self.num_heads, dim=1)\n",
        "            q_b, k_b, v_b = qkv_bias.split(self.channels // self.num_heads, dim=1)\n",
        "\n",
        "            self.query.weight.data = q_w.reshape(-1, self.channels)\n",
        "            self.key.weight.data = k_w.reshape(-1, self.channels)\n",
        "            self.value.weight.data = v_w.reshape(-1, self.channels)\n",
        "\n",
        "            self.query.bias.data = q_b.reshape(-1)\n",
        "            self.key.bias.data = k_b.reshape(-1)\n",
        "            self.value.bias.data = v_b.reshape(-1)\n",
        "\n",
        "            self.proj_attn.weight.data = attn_layer.proj.weight.data[:, :, 0]\n",
        "            self.proj_attn.bias.data = attn_layer.proj.bias.data\n",
        "\n",
        "class UNetMidBlock2D(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        temb_channels: int,\n",
        "        dropout: float = 0.0,\n",
        "        num_layers: int = 1,\n",
        "        resnet_eps: float = 1e-6,\n",
        "        resnet_time_scale_shift: str = \"default\",\n",
        "        resnet_act_fn: str = \"swish\",\n",
        "        resnet_groups: int = 32,\n",
        "        resnet_pre_norm: bool = True,\n",
        "        attn_num_head_channels=1,\n",
        "        attention_type=\"default\",\n",
        "        output_scale_factor=1.0,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention_type = attention_type\n",
        "        resnet_groups = resnet_groups if resnet_groups is not None else min(in_channels // 4, 32)\n",
        "\n",
        "        # there is always at least one resnet\n",
        "        resnets = [\n",
        "            ResnetBlock(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=in_channels,\n",
        "                temb_channels=temb_channels,\n",
        "                eps=resnet_eps,\n",
        "                groups=resnet_groups,\n",
        "                dropout=dropout,\n",
        "                time_embedding_norm=resnet_time_scale_shift,\n",
        "                non_linearity=resnet_act_fn,\n",
        "                output_scale_factor=output_scale_factor,\n",
        "                pre_norm=resnet_pre_norm,\n",
        "            )\n",
        "        ]\n",
        "        attentions = []\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            attentions.append(\n",
        "                AttentionBlockNew(\n",
        "                    in_channels,\n",
        "                    num_head_channels=attn_num_head_channels,\n",
        "                    rescale_output_factor=output_scale_factor,\n",
        "                    eps=resnet_eps,\n",
        "                    num_groups=resnet_groups,\n",
        "                )\n",
        "            )\n",
        "            resnets.append(\n",
        "                ResnetBlock(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=in_channels,\n",
        "                    temb_channels=temb_channels,\n",
        "                    eps=resnet_eps,\n",
        "                    groups=resnet_groups,\n",
        "                    dropout=dropout,\n",
        "                    time_embedding_norm=resnet_time_scale_shift,\n",
        "                    non_linearity=resnet_act_fn,\n",
        "                    output_scale_factor=output_scale_factor,\n",
        "                    pre_norm=resnet_pre_norm,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.attentions = nn.ModuleList(attentions)\n",
        "        self.resnets = nn.ModuleList(resnets)\n",
        "\n",
        "    def forward(self, hidden_states, temb=None, encoder_states=None):\n",
        "        hidden_states = self.resnets[0](hidden_states, temb)\n",
        "        for attn, resnet in zip(self.attentions, self.resnets[1:]):\n",
        "            if self.attention_type == \"default\":\n",
        "                hidden_states = attn(hidden_states)\n",
        "            else:\n",
        "                hidden_states = attn(hidden_states, encoder_states)\n",
        "            hidden_states = resnet(hidden_states, temb)\n",
        "\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=3,\n",
        "        out_channels=4,\n",
        "        down_block_types=(\"DownEncoderBlock2D\",),\n",
        "        block_out_channels=(64,),\n",
        "        layers_per_block=1,\n",
        "        act_fn=\"silu\",\n",
        "        double_z=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.layers_per_block = layers_per_block\n",
        "        self.conv_in = torch.nn.Conv2d(in_channels, block_out_channels[0], kernel_size=3, stride=1, padding=1)\n",
        "        self.mid_block = None\n",
        "        self.down_blocks = nn.ModuleList([])\n",
        "\n",
        "        # down\n",
        "        output_channel = block_out_channels[0]\n",
        "        for i, _ in enumerate(down_block_types):\n",
        "            input_channel = output_channel\n",
        "            output_channel = block_out_channels[i]\n",
        "            is_final_block = i == len(block_out_channels) - 1\n",
        "\n",
        "            down_block = DownEncoderBlock2D(\n",
        "                num_layers=self.layers_per_block,\n",
        "                in_channels=input_channel,\n",
        "                out_channels=output_channel,\n",
        "                add_downsample=not is_final_block,\n",
        "                resnet_eps=1e-6,\n",
        "                resnet_act_fn=act_fn,\n",
        "                downsample_padding=0,)\n",
        "\n",
        "            self.down_blocks.append(down_block)\n",
        "\n",
        "        # mid\n",
        "        self.mid_block = UNetMidBlock2D(\n",
        "            in_channels=block_out_channels[-1],\n",
        "            resnet_eps=1e-6,\n",
        "            resnet_act_fn=act_fn,\n",
        "            output_scale_factor=1,\n",
        "            resnet_time_scale_shift=\"default\",\n",
        "            attn_num_head_channels=None,\n",
        "            resnet_groups=32,\n",
        "            temb_channels=None,\n",
        "        )\n",
        "\n",
        "        # out\n",
        "        num_groups_out = 32\n",
        "        self.conv_norm_out = nn.GroupNorm(num_channels=block_out_channels[-1], num_groups=num_groups_out, eps=1e-6)\n",
        "        self.conv_act = nn.SiLU()\n",
        "\n",
        "        conv_out_channels = 2 * out_channels if double_z else out_channels\n",
        "        self.conv_out = nn.Conv2d(block_out_channels[-1], conv_out_channels, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        sample = x\n",
        "        sample = self.conv_in(sample)\n",
        "        \n",
        "        # down\n",
        "        for down_block in self.down_blocks:\n",
        "            sample = down_block(sample)\n",
        "\n",
        "        # middle\n",
        "        sample = self.mid_block(sample)\n",
        "\n",
        "        # post-process\n",
        "        sample = self.conv_norm_out(sample)\n",
        "        sample = self.conv_act(sample)\n",
        "        sample = self.conv_out(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=3,\n",
        "        out_channels=3,\n",
        "        up_block_types=(\"UpDecoderBlock2D\",),\n",
        "        block_out_channels=(64,),\n",
        "        layers_per_block=2,\n",
        "        act_fn=\"silu\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.layers_per_block = layers_per_block\n",
        "\n",
        "        self.conv_in = nn.Conv2d(in_channels, block_out_channels[-1], kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.mid_block = None\n",
        "        self.up_blocks = nn.ModuleList([])\n",
        "\n",
        "        # mid\n",
        "        self.mid_block = UNetMidBlock2D(\n",
        "            in_channels=block_out_channels[-1],\n",
        "            resnet_eps=1e-6,\n",
        "            resnet_act_fn=act_fn,\n",
        "            output_scale_factor=1,\n",
        "            resnet_time_scale_shift=\"default\",\n",
        "            attn_num_head_channels=None,\n",
        "            resnet_groups=32,\n",
        "            temb_channels=None,\n",
        "        )\n",
        "\n",
        "        # up\n",
        "        reversed_block_out_channels = list(reversed(block_out_channels))\n",
        "        output_channel = reversed_block_out_channels[0]\n",
        "        for i, up_block_type in enumerate(up_block_types):\n",
        "            prev_output_channel = output_channel\n",
        "            output_channel = reversed_block_out_channels[i]\n",
        "\n",
        "            is_final_block = i == len(block_out_channels) - 1\n",
        "\n",
        "            up_block = UpDecoderBlock2D(\n",
        "            num_layers=self.layers_per_block + 1,\n",
        "            in_channels=prev_output_channel,\n",
        "            out_channels=output_channel,\n",
        "            add_upsample=not is_final_block,\n",
        "            resnet_eps=1e-6,\n",
        "            resnet_act_fn=act_fn,\n",
        "        )\n",
        "\n",
        "            self.up_blocks.append(up_block)\n",
        "            prev_output_channel = output_channel\n",
        "\n",
        "        # out\n",
        "        num_groups_out = 32\n",
        "        self.conv_norm_out = nn.GroupNorm(num_channels=block_out_channels[0], num_groups=num_groups_out, eps=1e-6)\n",
        "        self.conv_act = nn.SiLU()\n",
        "        self.conv_out = nn.Conv2d(block_out_channels[0], out_channels, 3, padding=1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        sample = z\n",
        "        sample = self.conv_in(sample)\n",
        "\n",
        "        # middle\n",
        "        sample = self.mid_block(sample)\n",
        "\n",
        "        # up\n",
        "        for up_block in self.up_blocks:\n",
        "            sample = up_block(sample)\n",
        "\n",
        "        # post-process\n",
        "        sample = self.conv_norm_out(sample)\n",
        "        sample = self.conv_act(sample)\n",
        "        sample = self.conv_out(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "5_K2AE--WiX4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiagonalGaussianDistribution(object):\n",
        "    def __init__(self, parameters, deterministic=False):\n",
        "        self.parameters = parameters\n",
        "        self.mean, self.logvar = torch.chunk(parameters, 2, dim=1)\n",
        "        self.logvar = torch.clamp(self.logvar, -30.0, 20.0)\n",
        "        self.deterministic = deterministic\n",
        "        self.std = torch.exp(0.5 * self.logvar)\n",
        "        self.var = torch.exp(self.logvar)\n",
        "        if self.deterministic:\n",
        "            self.var = self.std = torch.zeros_like(self.mean).to(device=self.parameters.device)\n",
        "\n",
        "    def sample(self):\n",
        "        x = self.mean + self.std * torch.randn(self.mean.shape).to(device=self.parameters.device)\n",
        "        return x\n",
        "\n",
        "    def kl(self, other=None):\n",
        "        if self.deterministic:\n",
        "            return torch.Tensor([0.0])\n",
        "        else:\n",
        "            if other is None:\n",
        "                return 0.5 * torch.sum(torch.pow(self.mean, 2) + self.var - 1.0 - self.logvar, dim=[1, 2, 3])\n",
        "            else:\n",
        "                return 0.5 * torch.sum(\n",
        "                    torch.pow(self.mean - other.mean, 2) / other.var\n",
        "                    + self.var / other.var\n",
        "                    - 1.0\n",
        "                    - self.logvar\n",
        "                    + other.logvar,\n",
        "                    dim=[1, 2, 3],\n",
        "                )\n",
        "\n",
        "    def nll(self, sample, dims=[1, 2, 3]):\n",
        "        if self.deterministic:\n",
        "            return torch.Tensor([0.0])\n",
        "        logtwopi = np.log(2.0 * np.pi)\n",
        "        return 0.5 * torch.sum(logtwopi + self.logvar + torch.pow(sample - self.mean, 2) / self.var, dim=dims)\n",
        "\n",
        "    def mode(self):\n",
        "        return self.mean\n",
        "\n",
        "\n",
        "\n",
        "encoder = Encoder(in_channels=3,\n",
        "        out_channels=4,\n",
        "        down_block_types=(\"DownEncoderBlock2D\",),\n",
        "        block_out_channels=(64,),\n",
        "        layers_per_block=1,\n",
        "        act_fn=\"silu\",\n",
        "        double_z=True)\n",
        "\n",
        "\n",
        "decoder = Decoder(in_channels=4,\n",
        "            out_channels=3,\n",
        "            up_block_types=(\"UpDecoderBlock2D\",),\n",
        "            block_out_channels=(64,),\n",
        "            layers_per_block=1,\n",
        "            act_fn=\"silu\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ##########################\n",
        "    ##########################\n",
        "    ##########################\n",
        "#### AutoEncoder wrap- up class ####\n",
        "    ##########################\n",
        "    ##########################\n",
        "    ##########################\n",
        "\n",
        "class AutoencoderKL(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=3,\n",
        "        out_channels=3,\n",
        "        down_block_types=(\"DownEncoderBlock2D\",\"DownEncoderBlock2D\",\"DownEncoderBlock2D\",\"DownEncoderBlock2D\",),\n",
        "        up_block_types=(\"UpDecoderBlock2D\",\"UpDecoderBlock2D\",\"UpDecoderBlock2D\",\"UpDecoderBlock2D\",),\n",
        "        block_out_channels=(128, 256, 512, 512,),\n",
        "        layers_per_block=2,\n",
        "        act_fn=\"silu\",\n",
        "        latent_channels=4,\n",
        "        sample_size=512,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # pass init params to Encoder\n",
        "        self.encoder = Encoder(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=latent_channels,\n",
        "            down_block_types=down_block_types,\n",
        "            block_out_channels=block_out_channels,\n",
        "            layers_per_block=layers_per_block,\n",
        "            act_fn=act_fn,\n",
        "            double_z=True,\n",
        "        )\n",
        "\n",
        "        # pass init params to Decoder\n",
        "        self.decoder = Decoder(\n",
        "            in_channels=latent_channels,\n",
        "            out_channels=out_channels,\n",
        "            up_block_types=up_block_types,\n",
        "            block_out_channels=block_out_channels,\n",
        "            layers_per_block=layers_per_block,\n",
        "            act_fn=act_fn,\n",
        "        )\n",
        "\n",
        "        self.quant_conv = torch.nn.Conv2d(2 * latent_channels, 2 * latent_channels, 1)\n",
        "        self.post_quant_conv = torch.nn.Conv2d(latent_channels, latent_channels, 1) \n",
        "        self.kl = 0\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        moments = self.quant_conv(h)\n",
        "        posterior = DiagonalGaussianDistribution(moments)\n",
        "        return posterior\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.post_quant_conv(z)\n",
        "        dec = self.decoder(z)\n",
        "        return dec\n",
        "\n",
        "    def forward(self, sample, sample_posterior=False):\n",
        "        x = sample\n",
        "        posterior = self.encode(x)\n",
        "        if sample_posterior:\n",
        "            z = posterior.sample()\n",
        "        else:\n",
        "            z = posterior.mode()\n",
        "        dec = self.decode(z)\n",
        "        self.kl=posterior.kl()\n",
        "        return dec\n"
      ],
      "metadata": {
        "id": "wpwvB6BhWvDF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training function**"
      ],
      "metadata": {
        "id": "crEhgj4FVZTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### train\n",
        "from tqdm import tqdm\n",
        "PATH = './vae_net.pth'\n",
        "losses=[]\n",
        "def train(autoencoder, data, epochs=20,exp=None):\n",
        "\n",
        "    def adjust(sample):\n",
        "        # sample=np.expand_dims(np.asarray(sample), axis=0)\n",
        "        sample=sample.numpy()/ 1.0\n",
        "        # sample=sample.astype('float32')\n",
        "        sample = torch.from_numpy(sample).float() # Batch - RGB channel - WxH \n",
        "        sample = 2 * (sample - 0.5) # values between (-1, 1)\n",
        "        return sample\n",
        "\n",
        "    if not exp:\n",
        "        model_file='./{}_net.pth'.format(exp)\n",
        "    else:\n",
        "        model_file=PATH\n",
        "    \n",
        "    global opt\n",
        "    opt = torch.optim.Adam(autoencoder.parameters())\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.9)\n",
        "    epoch = 0\n",
        "\n",
        "    if os.path.exists(model_file):\n",
        "      checkpoint = torch.load(model_file)\n",
        "      autoencoder.load_state_dict(checkpoint['model_state_dict'])\n",
        "      opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "      epoch = checkpoint['epoch']\n",
        "      loss = checkpoint['loss']\n",
        "\n",
        "    for epoch in range(epoch, epochs):\n",
        "        print(\"Log epoch:\",epoch)\n",
        "        for i,x in enumerate(tqdm(data,total=len(data))):\n",
        "            x=adjust(x[0]) # Values between -1..1 \n",
        "            x = torch.Tensor(x).to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat = autoencoder(x)\n",
        "            loss = ((x - x_hat)**2).sum() + autoencoder.kl.sum()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            loss=loss.item()\n",
        "            losses.append(loss)\n",
        "            print(loss)\n",
        "\n",
        "            if not i % 300 and i != 0: \n",
        "                torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': autoencoder.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "                'loss': loss,\n",
        "                'scheduler':scheduler.state_dict()}, model_file)\n",
        "                print(\"model saved!\")\n",
        "        \n",
        "        scheduler.step()\n",
        "        torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': autoencoder.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "                'loss': loss,\n",
        "                'scheduler':scheduler.state_dict()}, model_file)\n",
        "        print(\"model saved!\")\n",
        "   \n",
        "    return autoencoder,losses"
      ],
      "metadata": {
        "id": "hieXAg7cVX-x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataLoader Cifar10** "
      ],
      "metadata": {
        "id": "AKgZYAGTVpnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ToDo: https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb\n",
        "# normalize dataset.\n",
        "\n",
        "def load_data(BS=32,path = \"./cifar-10-batches-py\"):\n",
        "    train = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.CIFAR10(path,\n",
        "               transform=torchvision.transforms.ToTensor(),\n",
        "               download=True),\n",
        "        batch_size=32,\n",
        "        shuffle=True)\n",
        "    \n",
        "    test = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.CIFAR10(path,\n",
        "               transform=torchvision.transforms.ToTensor(),\n",
        "               download=True,train=False),\n",
        "        batch_size=32,\n",
        "        shuffle=True)\n",
        "        \n",
        "    print(train.dataset)\n",
        "    print(test.dataset)\n",
        "    print(\"train data size:\",next(iter(train))[0].size())\n",
        "\n",
        "    return train,test\n"
      ],
      "metadata": {
        "id": "0ZSbEP8ik-CG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train/Test Split**\n"
      ],
      "metadata": {
        "id": "dVGV1ZUMj7Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data=load_data(BS=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC6eRUf5kACL",
        "outputId": "a2fb453a-b17b-4247-9d62-abd64d408f5e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./cifar-10-batches-py\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./cifar-10-batches-py\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "train data size: torch.Size([32, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Variational AutoEncoder on Cifar10 data."
      ],
      "metadata": {
        "id": "KWrWRwtFA6hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data=load_data(BS=32)\n",
        "vae=AutoencoderKL().to(device)\n",
        "vae, = train(vae, train_data,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sPWD7vMck51E",
        "outputId": "bcae9cbf-d732-49c0-d1da-09fed2809a01"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./cifar-10-batches-py\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./cifar-10-batches-py\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "train data size: torch.Size([32, 3, 32, 32])\n",
            "Log epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1563 [00:01<51:56,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37015.4296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/1563 [00:02<25:52,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135505.4375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/1563 [00:02<17:23,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52355.32421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 4/1563 [00:02<13:26,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34653.9921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 5/1563 [00:03<11:15,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25798.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 6/1563 [00:03<09:57,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23702.44140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 7/1563 [00:03<09:05,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23675.087890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 8/1563 [00:03<08:32,  3.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25240.40234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 9/1563 [00:04<08:09,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22291.197265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 10/1563 [00:04<07:54,  3.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25406.845703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 11/1563 [00:04<07:43,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28234.75390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 12/1563 [00:05<07:36,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24381.884765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 13/1563 [00:05<07:31,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21217.302734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 14/1563 [00:05<07:29,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26698.197265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 15/1563 [00:05<07:26,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28375.533203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 16/1563 [00:06<07:23,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25223.083984375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 17/1563 [00:06<07:23,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23683.904296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 18/1563 [00:06<07:20,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25976.865234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 19/1563 [00:07<07:19,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25920.087890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 20/1563 [00:07<07:22,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27746.609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 21/1563 [00:07<07:20,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25268.76953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 22/1563 [00:07<07:18,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21919.38671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 23/1563 [00:08<07:18,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26218.79296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 24/1563 [00:08<07:17,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22423.447265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 25/1563 [00:08<07:16,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27849.259765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 26/1563 [00:09<07:16,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24169.828125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 27/1563 [00:09<07:16,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28161.90234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 28/1563 [00:09<07:15,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23832.826171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 29/1563 [00:09<07:15,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24113.349609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 30/1563 [00:10<07:15,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23844.86328125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 31/1563 [00:10<07:15,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25176.431640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 32/1563 [00:10<07:15,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28407.640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 33/1563 [00:11<07:14,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21437.46484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 34/1563 [00:11<07:15,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26978.576171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 35/1563 [00:11<07:14,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23387.9296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 36/1563 [00:11<07:15,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24252.634765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 37/1563 [00:12<07:20,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24091.978515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 38/1563 [00:12<07:17,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23401.478515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 39/1563 [00:12<07:16,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25556.66796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 40/1563 [00:13<07:16,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20051.755859375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 41/1563 [00:13<07:15,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20560.658203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 42/1563 [00:13<07:14,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28784.841796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 43/1563 [00:13<07:13,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21841.515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 44/1563 [00:14<07:13,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22150.318359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 45/1563 [00:14<07:12,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26010.7890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 46/1563 [00:14<07:12,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26961.615234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 47/1563 [00:15<07:12,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25008.4140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 48/1563 [00:15<07:11,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25341.373046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 49/1563 [00:15<07:10,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24261.87890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 50/1563 [00:15<07:10,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23943.310546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 51/1563 [00:16<07:10,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25314.662109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 52/1563 [00:16<07:11,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24212.0546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 53/1563 [00:16<07:11,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20816.421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 54/1563 [00:17<07:10,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25024.021484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 55/1563 [00:17<07:10,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25053.00390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 56/1563 [00:17<07:12,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27896.822265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 57/1563 [00:17<07:10,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25854.001953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 58/1563 [00:18<07:09,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23760.052734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 59/1563 [00:18<07:08,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22872.201171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 60/1563 [00:18<07:07,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28135.4921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 61/1563 [00:19<07:07,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19136.38671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 62/1563 [00:19<07:06,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25915.91015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 63/1563 [00:19<07:05,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25261.701171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 64/1563 [00:19<07:06,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25234.201171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 65/1563 [00:20<07:07,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25909.46875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 66/1563 [00:20<07:07,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23374.603515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 67/1563 [00:20<07:06,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22256.1875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 68/1563 [00:21<07:07,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23912.873046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 69/1563 [00:21<07:07,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26175.0390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 70/1563 [00:21<07:07,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24240.73828125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 71/1563 [00:21<07:06,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23180.201171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 72/1563 [00:22<07:06,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24718.720703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 73/1563 [00:22<07:05,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23126.373046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 74/1563 [00:22<07:05,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23889.408203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 75/1563 [00:23<07:05,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23768.416015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 76/1563 [00:23<07:05,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23625.376953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 77/1563 [00:23<07:04,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21729.552734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 78/1563 [00:23<07:05,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26871.41015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 79/1563 [00:24<07:06,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22251.466796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 80/1563 [00:24<07:05,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18986.58203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 81/1563 [00:24<07:04,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23378.052734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 82/1563 [00:25<07:04,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24706.556640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 83/1563 [00:25<07:03,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24218.033203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 84/1563 [00:25<07:02,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25987.185546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 85/1563 [00:25<07:03,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24920.431640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 86/1563 [00:26<07:03,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26512.3125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 87/1563 [00:26<07:01,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22895.470703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 88/1563 [00:26<07:02,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24620.857421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 89/1563 [00:27<07:03,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25461.845703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 90/1563 [00:27<07:04,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19364.263671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 91/1563 [00:27<07:04,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23906.060546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 92/1563 [00:27<07:03,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25543.416015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 93/1563 [00:28<07:03,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24510.96875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 94/1563 [00:28<07:02,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25157.921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 95/1563 [00:28<07:03,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22859.29296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 96/1563 [00:29<07:02,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21863.578125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 97/1563 [00:29<07:02,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20037.21875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 98/1563 [00:29<07:01,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21713.888671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 99/1563 [00:29<07:02,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19373.13671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 100/1563 [00:30<07:03,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22056.861328125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 101/1563 [00:30<07:02,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22592.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 102/1563 [00:30<07:02,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23630.296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 103/1563 [00:31<07:01,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20647.3203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 104/1563 [00:31<07:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22584.994140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 105/1563 [00:31<06:59,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22213.158203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 106/1563 [00:32<07:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28088.359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 107/1563 [00:32<06:59,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19539.34375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 108/1563 [00:32<06:59,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21200.572265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 109/1563 [00:32<06:59,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24401.296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 110/1563 [00:33<06:57,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17005.01953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 111/1563 [00:33<06:57,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18430.162109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 112/1563 [00:33<06:56,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18006.994140625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 113/1563 [00:34<06:56,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18796.7421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 114/1563 [00:34<06:57,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19360.560546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 115/1563 [00:34<06:56,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20141.80078125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 116/1563 [00:34<06:56,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19481.6171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 117/1563 [00:35<06:56,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22263.912109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 118/1563 [00:35<06:55,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21234.0546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 119/1563 [00:35<06:55,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27022.6953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 120/1563 [00:36<06:55,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20204.33203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 121/1563 [00:36<06:54,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23318.169921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 122/1563 [00:36<06:54,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18731.19921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 123/1563 [00:36<06:54,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18356.142578125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 124/1563 [00:37<06:54,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22023.123046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 125/1563 [00:37<06:53,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18585.623046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 126/1563 [00:37<06:53,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20519.466796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 127/1563 [00:38<07:11,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16991.2109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-03b43d020b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAutoencoderKL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-0f81ff924e4e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(autoencoder, data, epochs, exp)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the results"
      ],
      "metadata": {
        "id": "M0mzai9XC-kF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_imgs = next(iter(data))[0]\n",
        "img=batch_imgs[2]"
      ],
      "metadata": {
        "id": "WNF-e-xiC-2P"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "def decode_img(img):\n",
        "    from PIL import Image\n",
        "    img = (img / 2 + 0.5).clamp(0, 1)\n",
        "    img = img.detach().cpu().permute(1, 2, 0).numpy()\n",
        "    img = (img * 255).round().astype('uint8')\n",
        "    pil_image = Image.fromarray(img)\n",
        "    return pil_image"
      ],
      "metadata": {
        "id": "8XpNYhETpyvG"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_img(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "f_A8abVtqv0j",
        "outputId": "2131b452-0dfa-4df6-8716-d933d77e54b2"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FBDE1A34D10>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output=vae(adjust(torch.Tensor(img)[None, :]).to(device))[0]"
      ],
      "metadata": {
        "id": "gk7rLY7FqzbZ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSsuvVVsmDHP",
        "outputId": "e6a077f4-2ef9-44a3-c49c-67e5850a7104"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3B912dn5lAc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}